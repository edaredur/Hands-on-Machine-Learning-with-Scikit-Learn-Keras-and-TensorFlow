{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
    "\n",
    "**Reference:** Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (Aurélien Géron)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Chapter Introduction\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning dense representations of the input data, called *latent representations* or *codings*, without any supervision (i.e., the training set is unlabeled). These codings typically have a much lower dimensionality than the input data, making autoencoders useful for dimensionality reduction, especially for visualization purposes. Autoencoders also act as feature detectors, and they can be used for unsupervised pretraining of deep neural networks. Lastly, some autoencoders are *generative models*: they are capable of randomly generating new data that looks very similar to the training data. For example, you could train an autoencoder on pictures of faces, and it would then be able to generate new faces.\n",
    "\n",
    "In contrast, faces generated by Generative Adversarial Networks (GANs) are now so convincing that it is hard to believe that the people they represent do not exist. GANs are now widely used for super resolution, colorizing black and white images, image editing, and turning sketches into photorealistic images.\n",
    "\n",
    "In this chapter, we will start by exploring how autoencoders work and how to use them for dimensionality reduction, feature extraction, unsupervised pretraining, and visualization. Then we will move on to Variational Autoencoders (VAEs) and finally GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Efficient Data Representations\n",
    "\n",
    "An autoencoder always consists of two parts: an **encoder** (recognition network) that converts the inputs to a latent representation, and a **decoder** (generative network) that converts the internal representation back to the inputs.\n",
    "\n",
    "As you can see, an autoencoder typically has the same architecture as a Multi-Layer Perceptron (MLP), except that the number of neurons in the output layer must be equal to the number of inputs. The outputs are often called the *reconstructions*. The cost function contains a *reconstruction loss* that penalizes the model when the reconstructions are different from the inputs.\n",
    "\n",
    "If an autoencoder were simply composed of linear activations and the cost function was the Mean Squared Error (MSE), then it would end up performing Principal Component Analysis (PCA). Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Generate 3D dataset\n",
    "np.random.seed(4) # Reproducibility\n",
    "m = 200\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "data = np.empty((m, 3))\n",
    "data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(data[:100])\n",
    "X_test = scaler.transform(data[100:])\n",
    "\n",
    "# Build Linear Autoencoder (PCA)\n",
    "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
    "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
    "history = autoencoder.fit(X_train, X_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stacked Autoencoders\n",
    "\n",
    "Just like other neural networks, autoencoders can have multiple hidden layers. In this case, they are called *Stacked Autoencoders* (or Deep Autoencoders). Adding more layers helps the autoencoder learn more complex features. However, one must be careful not to make the autoencoder too powerful. If the encoder is too powerful, it will just learn to copy the input to the output without learning any useful representation (overfitting).\n",
    "\n",
    "Let's build a stacked autoencoder for Fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "# Stacked Autoencoder Architecture\n",
    "# Encoder: 784 -> 100 -> 30\n",
    "# Decoder: 30 -> 100 -> 784\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "# Compile (using binary_crossentropy because pixel values are 0-1)\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=1.5), metrics=[])\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Reconstructions\n",
    "\n",
    "One way to ensure the autoencoder has learned properly is to compare the inputs and the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "\n",
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convolutional Autoencoders\n",
    "\n",
    "If you are dealing with images, autoencoders using dense layers will not work very well (they ignore spatial structure). You should use Convolutional Autoencoders. The encoder will use regular `Conv2D` layers (usually with strides to reduce spatial dimensionality), and the decoder will use `Conv2DTranspose` layers (to upsample and restore dimensionality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = keras.models.Sequential([\n",
    "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2)\n",
    "])\n",
    "conv_decoder = keras.models.Sequential([\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\",\n",
    "                                 input_shape=[3, 3, 64]),\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
    "\n",
    "conv_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "                metrics=[\"accuracy\"])\n",
    "# history = conv_ae.fit(X_train, X_train, epochs=5, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recurrent Autoencoders\n",
    "\n",
    "If you want to build an autoencoder for sequences (e.g., time series or text), you can use Recurrent Neural Networks. The encoder is typically a sequence-to-vector RNN which compresses the input sequence into a single state vector. The decoder is a vector-to-sequence RNN that repeats this vector and generates the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_encoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
    "    keras.layers.LSTM(30)\n",
    "])\n",
    "recurrent_decoder = keras.models.Sequential([\n",
    "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
    "])\n",
    "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
    "# recurrent_ae.compile(...) # Compilation is similar to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Denoising Autoencoders\n",
    "\n",
    "Another way to force the autoencoder to learn useful features is to add noise to its inputs, training it to recover the original, noise-free inputs. This prevents the autoencoder from trivially copying its inputs to its outputs and forces it to find patterns in the data.\n",
    "\n",
    "The noise can be pure Gaussian noise added to the inputs, or it can be randomly switching off inputs (like Dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "dropout_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
    "dropout_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "                   metrics=[\"accuracy\"])\n",
    "history = dropout_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Variational Autoencoders (VAEs)\n",
    "\n",
    "Variational autoencoders differ from regular autoencoders in two ways:\n",
    "1.  They are **probabilistic** autoencoders: their outputs are partly determined by chance, even after training.\n",
    "2.  They are **generative** autoencoders: they can generate new instances that look like they were sampled from the training set.\n",
    "\n",
    "Instead of directly producing a coding for a given input, the encoder produces a *mean coding* $\\mu$ and a *standard deviation* $\\sigma$. The actual coding is then sampled from a Gaussian distribution with mean $\\mu$ and standard deviation $\\sigma$. The decoder then decodes the sampled coding.\n",
    "\n",
    "The cost function is composed of two parts:\n",
    "1.  **Reconstruction loss:** forces the autoencoder to reproduce its inputs.\n",
    "2.  **Latent loss:** pushes the autoencoder to have codings that look as though they were sampled from a simple Gaussian distribution (KL Divergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return keras.backend.random_normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z)\n",
    "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.models.Model(\n",
    "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "\n",
    "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
    "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "vae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "\n",
    "latent_loss = -0.5 * keras.backend.sum(\n",
    "    1 + codings_log_var - keras.backend.exp(codings_log_var) - keras.backend.square(codings_mean),\n",
    "    axis=-1)\n",
    "vae.add_loss(keras.backend.mean(latent_loss) / 784.)\n",
    "vae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[])\n",
    "history = vae.fit(X_train, X_train, epochs=25, batch_size=128,\n",
    "                  validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generative Adversarial Networks (GANs)\n",
    "\n",
    "GANs were proposed by Ian Goodfellow in 2014. They consist of two networks:\n",
    "* **Generator:** Takes a random distribution as input (typically Gaussian) and outputs some data (e.g., an image). Its goal is to trick the discriminator into believing the output is real.\n",
    "* **Discriminator:** Takes either a fake image from the generator or a real image from the training set and outputs a probability that the image is real. Its goal is to distinguish real from fake.\n",
    "\n",
    "Training is a zero-sum game: the generator tries to minimize the discriminator's ability to distinguish, while the discriminator tries to maximize it.\n",
    "\n",
    "### Implementation (Simple GAN for Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 30\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False # To train the generator without affecting the discriminator\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(32, drop_remainder=True).prefetch(1)\n",
    "\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=5):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for X_batch in dataset:\n",
    "            # Phase 1 - Train Discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            \n",
    "            # Phase 2 - Train Generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size) # We want discriminator to think these are real\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "\n",
    "train_gan(gan, dataset, 32, codings_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}